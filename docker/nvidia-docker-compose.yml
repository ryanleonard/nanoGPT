version: '3.8'

services:
  nano-gpt-service:
    build: 
      context: ../
      dockerfile: docker/Dockerfile.nvidia
    tty: true
    stdin_open: true
    image: pytorch-nanogpt-cuda
    container_name: nanogpt
#    volumes:
#      - ../:/app
    ports:
      - "8888:8888"
    environment: 
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]

